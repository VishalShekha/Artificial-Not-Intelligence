{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f44310c9-c1f4-4c3a-98f4-565beec9a993",
   "metadata": {},
   "source": [
    "Hello World!\n",
    "This a initial level theory, math and code for ML using ANN.\n",
    "ANN - stands for \"artificial neural network\", a computation model inspried by the human neural network.\n",
    "ANN belongs to supervised learning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95cdc695-fd15-4d98-b860-2fd7e44b881a",
   "metadata": {},
   "source": [
    "A unit in a neutral network is a function that takes in input multiply it with it's weights and addes some baisis. To give an output.\n",
    "\n",
    "# z = i=0->n ∑xi*wi                \n",
    "\n",
    "then, a = f(z)\n",
    "f(x) is called a activition function.\n",
    "\n",
    "a output of a "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83abb1f3-a9a2-4f7e-a6d7-6deeff49c4f8",
   "metadata": {},
   "source": [
    "There are many activiton functions.\n",
    "\n",
    "What is Activation Function?\r",
    "    : \n",
    "It’s just a thing function that you use to get the output of node. It is also known as Transfer Function\r\n",
    "\n",
    "\r\n",
    "Why we use Activation functions with Neural Network    : s?\r\n",
    "It is used to determine the output of neural network like yes or no. It maps the resulting values in between 0 to 1 or -1 to 1 etc. (depeg ing  pon the functi\n",
    "\n",
    "There are two types of activition fucntion:\n",
    "    1. Linear Activition function\n",
    "    2. Non-Linear Activition function\n",
    "1. Linear Activition function\n",
    " \n",
    " a. Identity function :\n",
    "   Equation :  y = x\n",
    "   Uses : Linear activation function is used at just one place i.e. output layer.\r",
    "    For example : Calculation of price of a house is a regression problem. House price may have any big/small value, so we can apply linear activation at output layer. Even in this case neural net must have any non-linear function at hidden layers. \r\n",
    "2. Non-Linear Function\n",
    " \n",
    " a. \r\n",
    "Sigmoid Functio:\n",
    "    Equation : A = 1/(1 + e^-x)\r",
    "    Uses : Usually used in output layer of a binary classification, where result is either 0 or 1, as value for sigmoid function lies between 0 and 1 only so, result can be predicted easily to be 1 if value is greater than 0.5 and 0 otherwise.\n",
    " \n",
    " b. Tanh Function :\n",
    "    Equation : A = tanh(x) = [1/(1 + e^-2x)] -1\n",
    "    Uses :- Usually used in hidden layers of a neural network as it’s values lies between -1 to 1 hence the mean for the hidden layer comes out be 0 or very close to it, hence helps in centering the data by bringing mean close to 0. This makes learning for the next layer much easier.\n",
    " \n",
    " c. RELU Function :\n",
    "     Equation :- A(x) = max(0,x).\n",
    "     Uses :- ReLu is less computationally expensive than tanh and sigmoid because it involves simpler mathematical operations. At a time only a few neurons are activated making the network sparse making it efficient and easy for computation.\n",
    "\n",
    " d. Softmax Function : \n",
    "     Uses :- Usually used when trying to handle multiple classes. the softmax function was commonly found in the output layer of image classification problems.The softmax function would squeeze the outputs for each class between 0 and 1 and would also divide by the sum of the outputs. \n",
    "\n",
    "\n",
    "n \n",
    "on)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a9c99-d3ab-43b7-b551-a00f0fd6f56f",
   "metadata": {},
   "source": [
    "Gradient Descent:\n",
    "W -> weights\n",
    "B -> Baisis\n",
    "h -> prediction\n",
    "y -> label\n",
    "\n",
    "cost function to check error\n",
    "J(W, B) = (h-y)^2\n",
    "\n",
    "Cost of training set M.S.E :\n",
    "J(W, B) = 1/n*(i=0->n ∑(h^i - y^i)^2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7abdb341-754b-462b-9e00-9c261d314543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
